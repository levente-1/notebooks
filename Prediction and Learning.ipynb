{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Exercise\n",
    "\n",
    "## Part 1- File organisation\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Renaming files\n",
    "2. Creating folders\n",
    "3. Moving files to folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renameFiles(directory, filesPerSubject):\n",
    "    '''\n",
    "    Renames files in DATA folder, replacing subject initials with subject number \n",
    "    (organised via alphabetical order)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    directory -- string of directory pathway\n",
    "    filesPerSubject -- integer; number of files for each subject\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    '''\n",
    "    # Retrieve files in alphabetical order\n",
    "    myFiles = sorted(os.listdir(directory))\n",
    "    \n",
    "    # Following variable will allow for detection of new subject file, as opposed to additional file from same subject\n",
    "    isNew = 1\n",
    "    i = 1\n",
    "    \n",
    "    # Rename file according to alphabetical order\n",
    "    for filename in myFiles:\n",
    "        os.rename(os.path.join(directory,filename), os.path.join(directory,'00' + str(i) + str(filename[2:])))\n",
    "        \n",
    "        # If 'isNew' has not reached specified number of files per subject, add one\n",
    "        if isNew != filesPerSubject:\n",
    "            isNew += 1\n",
    "            \n",
    "        # If 'isNew' == number of files per subject, add 1 to i, as next file will correspond to a new subject\n",
    "        else:   \n",
    "            i += 1\n",
    "            isNew = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = ('/Users/levi/Downloads/DATA/')\n",
    "filesPerSubject = 2\n",
    " \n",
    "renameFiles(directory, filesPerSubject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFolders(parent_dir, numSubjects):\n",
    "    '''\n",
    "    Creates new folders to organise each subjects' data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    parent_dir -- string; the parent directory in which the new folders should be created\n",
    "    numSubjects -- integer; total number of subjects\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    folders -- list of strings containing name of each new folder created\n",
    "\n",
    "    '''\n",
    "    # Create list containing names of folders to be created\n",
    "    folders = []\n",
    "    for i in range(numSubjects):\n",
    "        folders.append('00'+str(i+1))\n",
    "\n",
    "    # For each folder in 'folders', create a new directory with this name\n",
    "    for folder in folders:\n",
    "        path = os.path.join(parent_dir, folder)\n",
    "        os.mkdir(path)\n",
    "    \n",
    "    # Return list of folder names for next function\n",
    "    return folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = ('/Users/levi/Downloads/DATA/')\n",
    "numSubjects = 5\n",
    "\n",
    "folders = createFolders(parent_dir, numSubjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupFiles(parent_dir, folders):\n",
    "    '''\n",
    "    Organise files into folders created by previous function\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    parent_dir : string; the parent directory in file organisation should occur\n",
    "    folders : list of folder names\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    '''\n",
    "    # Retrieve all files within given parent directory\n",
    "    myFiles = sorted(os.listdir(parent_dir))\n",
    "\n",
    "    for file in myFiles:\n",
    "        \n",
    "        # Identify the files with data (and ignore folders)\n",
    "        if file.endswith('.mat'):\n",
    "            sourcepath = os.path.join(parent_dir,file)\n",
    "            \n",
    "            # Identify which one of the folders matches with the file\n",
    "            match = folders[folders.index(file[0:3])]\n",
    "            \n",
    "            # Set this as the destination\n",
    "            destpath = parent_dir + match + '/' + file\n",
    "            shutil.move(sourcepath, destpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupFiles(parent_dir, folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Data visualisation.\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Loading files\n",
    "2. Graph of all subjects' reaction times\n",
    "3. Graph of all subjects' task outcome\n",
    "4. Average reaction times\n",
    "5. Average task outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "from scipy.stats import sem\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .mat files into Python IDE\n",
    "directory = ('/Users/levi/Downloads/DATA/')\n",
    "\n",
    "# Set up separate lists for task data and pupil data\n",
    "task = []\n",
    "pupil = []\n",
    "\n",
    "# Iterate through each subject folder (add  [1:] here to get rid of '.DS_Store')\n",
    "for folder in sorted(os.listdir(directory))[1:]:\n",
    "    \n",
    "    # Iterate through each file\n",
    "    newDirectory = os.path.join(directory,folder)\n",
    "    for file in sorted(os.listdir(newDirectory)):\n",
    "        \n",
    "        # If it is a task file, place it in task list\n",
    "        if file.endswith('task.mat'):\n",
    "            task.append(scipy.io.loadmat(os.path.join(newDirectory,file)))\n",
    "            \n",
    "         # If it is a pupil file, place it in task list\n",
    "        if file.endswith('pupil.mat'):\n",
    "            pupil.append(scipy.io.loadmat(os.path.join(newDirectory,file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToDict(matfiles):\n",
    "    '''\n",
    "    Extracts matrices from .mat files and places them into a dictionary, allowing for analysis within Python\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    matfiles - list containing .mat files\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    subjectDict - Dictionary containing matrix representation of data within each .mat file\n",
    "\n",
    "    '''\n",
    "    # Set up empty dictionary\n",
    "    subjectDict = {}\n",
    "    \n",
    "    # Iterate over .mat files\n",
    "    for i in range(len(matfiles)):\n",
    "        \n",
    "        # Final key in files stores the actual data structure; retrieve this\n",
    "        mainKey = (list(matfiles[i].keys()))[-1]\n",
    "        \n",
    "        # Add it into dictionary according under key of corresponding subject\n",
    "        subjectDict['00'+ str(i+1)] = matfiles[i][mainKey]\n",
    "    \n",
    "    return subjectDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskDict = convertToDict(task)\n",
    "print(taskDict['001'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGraph(subject, graphType):\n",
    "\n",
    "    xVals = np.arange(1,41)\n",
    "\n",
    "    yValsHard = subject[:40,2]\n",
    "    yValsEasy = subject[40:,2]\n",
    "\n",
    "    colormap = np.array(['blue','red', 'green'])\n",
    "\n",
    "    colorsHard = subject[:40,1]\n",
    "    colorsEasy = subject[40:,1]\n",
    "\n",
    "    def cleanColors(colors):\n",
    "        \n",
    "        for i in range(len(colors)):\n",
    "            if math.isnan(colors[i]):\n",
    "                colors[i] = 2\n",
    "        return colors\n",
    "    \n",
    "    colorsEasy = cleanColors(colorsEasy)\n",
    "    colorsHard = cleanColors(colorsHard)\n",
    "\n",
    "\n",
    "    def removeNaN(yVals):\n",
    "        for i in range(len(yVals)):\n",
    "            if math.isnan(yVals[i]):\n",
    "                yVals[i] = 0\n",
    "        return yVals\n",
    "\n",
    "    yValsEasy = removeNaN(yValsEasy)\n",
    "    yValsHard = removeNaN(yValsHard)\n",
    "\n",
    "    colorsEasy = colorsEasy.astype(int)\n",
    "    colorsHard = colorsHard.astype(int)\n",
    "\n",
    "    if graphType == 'scatter':\n",
    "        # #### Scatter plot representation\n",
    "        plt.subplot(2,1,1)\n",
    "        plt.scatter(xVals, yValsEasy, s=100, marker='<', c=colormap[colorsEasy])\n",
    "        plt.subplot(2,1,2)\n",
    "        plt.scatter(xVals, yValsHard, s=100, marker='<', c=colormap[colorsHard])\n",
    "\n",
    "\n",
    "    elif graphType == 'bar':\n",
    "        ### Bar graph representation\n",
    "        plt.subplot(2,1,1)\n",
    "        plt.bar(xVals, yValsEasy, color = colormap[colorsEasy])\n",
    "        plt.subplot(2,1,2)\n",
    "        plt.bar(xVals, yValsHard, color = colormap[colorsHard])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createGraph(taskDict['002'], 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual subject visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGraphReactions(subjectDict):\n",
    "    '''\n",
    "    Create grouped bar chart for each subject's average reaction time in each condition.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    subjectDict -- Dictionary containing each subject's data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    reactionsEasy -- list storing all five subject's avg reaction time in easy condition\n",
    "         \n",
    "    reactionsHard -- list storing all five subject's avg reaction time in hard condition\n",
    "       \n",
    "    These two lists are outputted as they will be of use for later function\n",
    "\n",
    "    '''\n",
    "    # Empty lists for average reactions\n",
    "    reactionsEasy = []\n",
    "    reactionsHard = []\n",
    "    \n",
    "    # Empty lists to store standard deviation\n",
    "    stdevEasy = []\n",
    "    stdevHard = []\n",
    "    \n",
    "    # Append each list with appropriate columns from data matrix\n",
    "    for subject in list(subjectDict.values()):\n",
    "        reactionsHard.append(subject[:40,2])\n",
    "        reactionsEasy.append(subject[40:,2])\n",
    "        \n",
    "        #Append 'stdev' lists with standard deviation of specified columns\n",
    "        stdevHard.append(np.nanstd(subject[:40,2]))\n",
    "        stdevEasy.append(np.nanstd(subject[40:,2]))\n",
    "    \n",
    "    # Convert values stored in 'reaction' lists to means\n",
    "    for i in range(len(reactionsEasy)):\n",
    "        reactionsEasy[i] = np.nanmean(reactionsEasy[i])\n",
    "        \n",
    "    for i in range(len(reactionsHard)):\n",
    "        reactionsHard[i] = np.nanmean(reactionsHard[i])\n",
    "        \n",
    "    # Set up X labels and X-axis, and plot data in grouped bar chart   \n",
    "    X = ['Subject 1','Subject 2', 'Subject 3', 'Subject 4', 'Subject 5']\n",
    "    X_axis = np.arange(len(X))\n",
    "    plt.bar(X_axis - 0.2, reactionsEasy, 0.4, label = 'Easy')\n",
    "    plt.bar(X_axis + 0.2, reactionsHard, 0.4, label = 'Hard')\n",
    "    \n",
    "    # Set up labels and legend\n",
    "    plt.xticks(X_axis, X)\n",
    "    plt.xlabel(\"Participant\", fontsize = 13)\n",
    "    plt.ylabel(\"Avg Reaction Time (miliseconds)\", fontsize = 13)\n",
    "    plt.title(\"Subject reaction time to cognitive task\", fontsize = 15)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Use standard deviations to plot variance \n",
    "    plt.errorbar(X_axis-0.2, reactionsEasy, yerr = stdevEasy, fmt = ' ', ecolor = 'black', capsize = 5)\n",
    "    plt.errorbar(X_axis+0.2, reactionsHard, yerr = stdevHard, fmt = ' ', ecolor = 'black', capsize = 5)\n",
    "    plt.show()\n",
    "    \n",
    "    # Return list of average reaction times\n",
    "    return reactionsEasy, reactionsHard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactionsEasy, reactionsHard = createGraphReactions(taskDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGraphOutcomes(subjectDict):\n",
    "    '''\n",
    "    Create grouped stacked bar chart how many trials of the cognitive task each subject completed,\n",
    "    and how many of these were correct/incorrect\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    subjectDict -- Dictionary containing each subject's data (same as function above)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    correctEasy -- List; total number of correct answers for each subject in Easy condition\n",
    "    correctHard -- List; total number of correct answers for each subject in Hard condition\n",
    "\n",
    "    '''\n",
    "    # Empty lists to story correct, incorrect, and missed for all subjects in each condition\n",
    "    correctEasy = []\n",
    "    incorrectEasy = []\n",
    "    missedEasy = []\n",
    "    \n",
    "    correctHard = []\n",
    "    incorrectHard = []\n",
    "    missedHard = []\n",
    "    \n",
    "    # Iterate over each subject to update lists above\n",
    "    for subject in list(subjectDict.values()):\n",
    "        correct = 0\n",
    "        incorrect = 0\n",
    "        missed = 0\n",
    "        \n",
    "        # Start with first 40 rows (Hard condition)\n",
    "        for i in subject[:40,1]:\n",
    "            if i == 0:\n",
    "                correct += 1\n",
    "            elif i == 1:\n",
    "                incorrect += 1\n",
    "            else:\n",
    "                missed += 1\n",
    "        correctHard.append(correct)\n",
    "        incorrectHard.append(incorrect)\n",
    "        missedHard.append(missed)\n",
    "        \n",
    "        # Reset counters\n",
    "        correct = 0\n",
    "        incorrect = 0\n",
    "        missed = 0\n",
    "        \n",
    "        # Second 40 rows (Easy condition)\n",
    "        for i in subject[40:,1]:\n",
    "            if i == 0:\n",
    "                correct += 1\n",
    "            elif i == 1:\n",
    "                incorrect += 1\n",
    "            else:\n",
    "                missed += 1\n",
    "        correctEasy.append(correct)\n",
    "        incorrectEasy.append(incorrect)\n",
    "        missedEasy.append(missed)\n",
    "    \n",
    "    # Set up X labels and X-axis\n",
    "    X = ['Subject 1','Subject 2', 'Subject 3', 'Subject 4', 'Subject 5']\n",
    "    X_axis = np.arange(len(X))\n",
    "    sns.set(style = 'darkgrid')\n",
    "    \n",
    "    # Plot Easy condition\n",
    "    plt.bar(X_axis - 0.2, correctEasy, 0.3, color = 'darkblue', alpha = 0.7)\n",
    "    plt.bar(X_axis - 0.2, incorrectEasy, 0.3, bottom=correctEasy, color = 'darkred', alpha = 0.7)\n",
    "    \n",
    "    # Plot Hard condition\n",
    "    plt.bar(X_axis + 0.2, correctHard, 0.3, color = 'darkblue', alpha = 0.7)\n",
    "    plt.bar(X_axis + 0.2, incorrectHard, 0.3, bottom=correctHard, color = 'darkred', alpha = 0.7)\n",
    "    \n",
    "    # Add labels\n",
    "    plt.xticks(X_axis, X)\n",
    "    plt.ylim(top = 48)\n",
    "    plt.xlabel('Participants', fontsize = 13)\n",
    "    plt.ylabel(\"Trials completed\", fontsize = 13)\n",
    "    plt.title(\"Success ratio of each subject in Cognitive Task\", fontsize = 13)\n",
    "   \n",
    "    # To clearly distinguish between Easy and Hard condition, labels are placed on top of each bar\n",
    "    # Below are helper functions to create labels for each condition\n",
    "    def addlabelsEasy(x,y):\n",
    "        for i in range(len(x)):\n",
    "            plt.text(x[i], y[i]+1, 'Easy', ha = 'center', fontsize = 'small')  \n",
    "    \n",
    "    def addlabelsHard(x,y):\n",
    "        for i in range(len(x)):\n",
    "            plt.text(x[i], y[i]+1, 'Hard', ha = 'center', fontsize = 'small')\n",
    "            \n",
    "    # X-coordinates for 'Easy' and 'Hard' labels, respectively\n",
    "    X1 = X_axis - 0.2\n",
    "    X2 = X_axis + 0.2\n",
    "    \n",
    "    # Y-coordinates for 'Easy' and 'Hard' labels, respectively\n",
    "    Y1 = np.add(correctEasy, incorrectEasy)\n",
    "    Y2 = np.add(correctHard, incorrectHard)\n",
    "    \n",
    "    # Add labels\n",
    "    addlabelsEasy(X1, Y1)\n",
    "    addlabelsHard(X2, Y2)\n",
    "    \n",
    "    # Place legend outside of figure\n",
    "    plt.legend(bbox_to_anchor=(0.6, 0.55, 0.5, 0.5), labels=['Correct', 'Incorrect'], fontsize = 'x-small')\n",
    "    plt.show()\n",
    "    \n",
    "    # Return list containing number of correct responses\n",
    "    return correctEasy, correctHard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctEasy, correctHard = createGraphOutcomes(taskDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data across five participants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(reactionsEasy)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(reactionsHard)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up list containing arrays of reaction times for Easy and Hard condition, respectively\n",
    "data = [reactionsEasy, reactionsHard]\n",
    "labels = ['Easy', 'Hard']\n",
    "\n",
    "# Set up subplots\n",
    "fig, ax = plt.subplots()\n",
    "medianprops = dict(linestyle='-', linewidth=2.5, color='firebrick')\n",
    "bplot = ax.boxplot(data, patch_artist = True, labels = labels, medianprops = medianprops)\n",
    "\n",
    "# Colour each plot differently\n",
    "colors = ['lightblue', 'tan']\n",
    "for patch, color in zip(bplot['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    \n",
    "# Add labels\n",
    "plt.xlabel('Experimental Condition', fontsize = 13)\n",
    "plt.ylabel(\"Reaction time (milliseconds\")\n",
    "plt.title(\"Reaction times in each condition\", fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAverageSuccess(correctEasy, correctHard):\n",
    "    '''\n",
    "    Obtain success rate in cognitive task for each subject by converting number of \n",
    "    correct responses to a percentage of total trials.\n",
    "    \n",
    "    This function treats missed responses as incorrect.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    correctEasy -- list containing number of correct responses for each subject in Easy condition\n",
    "    correctHard -- list containing number of correct responses for each subject in Hard condition\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    outcomeEasy -- list; percentage score of each subject in Easy condition\n",
    "    outcomeHard -- list; percentage score of each subject in Hard condition\n",
    "\n",
    "    '''\n",
    "    # Copy input lists so as not to alter them\n",
    "    outcomeEasy = correctEasy.copy()\n",
    "    outcomeHard = correctHard.copy()\n",
    "    \n",
    "    # Convert number of correct responses into percentage scores\n",
    "    for i in range(len(outcomeEasy)):\n",
    "        outcomeEasy[i] = outcomeEasy[i]/40\n",
    "        outcomeEasy[i] *= 100\n",
    "    for i in range(len(outcomeHard)):\n",
    "        outcomeHard[i] = outcomeHard[i]/40\n",
    "        outcomeHard[i] *= 100\n",
    "    \n",
    "    # Return percentages\n",
    "    return outcomeEasy, outcomeHard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomeEasy, outcomeHard = getAverageSuccess(correctEasy, correctHard)\n",
    "\n",
    "plt.hist(outcomeEasy)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(outcomeHard)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up list containing array of task outcomes for Easy and Hard condition, respectively\n",
    "data = [outcomeEasy, outcomeHard]\n",
    "labels = ['Easy', 'Hard']\n",
    "\n",
    "# Set up subplots\n",
    "fig, ax = plt.subplots()\n",
    "medianprops = dict(linestyle='-', linewidth=2.5, color='firebrick')\n",
    "bplot = ax.boxplot(data, patch_artist = True, labels = labels, medianprops = medianprops)\n",
    "\n",
    "# Colour each plot differently\n",
    "colors = ['lightgreen', 'lightgrey']\n",
    "for patch, color in zip(bplot['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "# Add labels\n",
    "plt.xlabel(\"Experimental Condition\", fontsize = 13)\n",
    "plt.ylabel(\"Success rate (percentage)\", fontsize = 13)\n",
    "plt.title(\"Successful responses to cogntive tasks\", fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Data cleaning\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Sample rate\n",
    "2. Cleaning before visualisation\n",
    "3. Cleaning after visualisation\n",
    "4. Comparing conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pupilDict = convertToDict(pupil)\n",
    "subject001 = pupilDict['001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subject001.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify sample rate\n",
    "\n",
    "# Select number of columns (-1, as first describes condition) and divide by 6 (seconds of recording)\n",
    "samplingRate = (subject001.shape[1]-1)/6\n",
    "\n",
    "print(\"Sample rate = \" + str(int(samplingRate)) + '/sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDataFrames(subject):\n",
    "    '''\n",
    "    Convert numpy matrix into pandas dataframe\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    subject - pupil data matrix of a single subject\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dfDark - data frame of pupillary data within Dark condition\n",
    "    dfLight - data frame of pupillary data within Light condition\n",
    "\n",
    "    '''\n",
    "    # First convert matrix into two dictionaries ('Dark' and 'Light')\n",
    "    # Start by setting up Dark Dictionary\n",
    "    subjectDictDark = {}\n",
    "    \n",
    "    # Identify number of rows (trials) for each condition\n",
    "    condition = subject.shape[0]//2\n",
    "    \n",
    "    # In Dark Dictionary, set each key to the corresponding trial (column)\n",
    "    for i in range(condition):\n",
    "        subjectDictDark['Trial_'+ str(i+1)] = subject001[i,1:]\n",
    "        \n",
    "    # Repeat process for Light Dictionary\n",
    "    subjectDictLight = {}\n",
    "    for i in range(condition,(condition*2)):\n",
    "        subjectDictLight['Trial_'+ str((i+1)-condition)] = subject001[i,1:]\n",
    "    \n",
    "    # Turn dictionaries into datframes\n",
    "    dfDark = pd.DataFrame(subjectDictDark)\n",
    "    dfLight = pd.DataFrame(subjectDictLight)\n",
    "    \n",
    "    return dfDark, dfLight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDark, dfLight = makeDataFrames(subject001)\n",
    "print(dfDark.head(10))\n",
    "print(dfLight.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffilled = dfDark.ffill(axis = 0)\n",
    "\n",
    "plt.plot(ffilled.Trial_1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dfDark.Trial_1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Trial 1 data (yields a pandas series)\n",
    "Trial1dark = dfDark.Trial_1.copy()\n",
    "\n",
    "# Rename this the 'Original', and convert back into dataframe\n",
    "Trial1dark = Trial1dark.rename('Original')\n",
    "df1 = Trial1dark.to_frame()\n",
    "\n",
    "# Add new column into dataframe, named 'Smoothed'\n",
    "# Perform interpolation, then exponentially-weighted moving average\n",
    "df1['Smoothed'] = df1['Original'].interpolate()\n",
    "df1['Smoothed'] = df1['Smoothed'].ewm(span = 200).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df1['Original'], label = 'Original')\n",
    "plt.plot(df1['Smoothed'], label = 'Cleaned')\n",
    "plt.xlabel(\"Time (miliseconds)\", fontsize = 13)\n",
    "plt.ylabel(\"Pupil measure\", fontsize = 13)\n",
    "plt.title(\"Pupil measure during dark screen\", fontsize = 15)\n",
    "plt.legend()\n",
    "plt.xlim(0, 6000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial1_Dark = dfDark.Trial_1.copy()\n",
    "t1Dark_array = trial1_Dark.values\n",
    "\n",
    "def avgFill(a):\n",
    "    '''\n",
    "    Own method of filling in data in areas where it is missing. As opposed to ffill or bfill, it results\n",
    "    in connection that is less aligned with peaks/troughs\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a -- array representation of data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    a -- filled array\n",
    "\n",
    "    '''\n",
    "    for i in range(len(a)):\n",
    "        # Identify nan\n",
    "        if math.isnan(a[i]):\n",
    "            \n",
    "            # If gap is at start of timeseries, only a small window can be calculated for a rolling average\n",
    "            if i < 100:\n",
    "                window = a[i-10:i-1]\n",
    "                rollAvg = np.mean(window)\n",
    "                a[i] = rollAvg\n",
    "                \n",
    "            # If the gap occurs later, a larger window can be indexed into\n",
    "            else:\n",
    "                window = a[i-100:i-1]\n",
    "                rollAvg = np.mean(window)\n",
    "                a[i] = rollAvg\n",
    "    return a\n",
    "\n",
    "t1Dark_array = avgFill(t1Dark_array)\n",
    "plt.xlim(0,6000)\n",
    "plt.plot(t1Dark_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect spikes using Z-score\n",
    "\n",
    "#### |z(i)| = |(x(i)-μ) / σ|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(y):\n",
    "    '''\n",
    "    Regular z-score; assess how far a value is from the mean in units of SD\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y -- array of data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    z_scores -- array of z-score values\n",
    "    \n",
    "    '''\n",
    "    mean_int = np.mean(y)\n",
    "    std_int = np.std(y)\n",
    "    z_scores = (y - mean_int) / std_int\n",
    "    return z_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores = np.array(abs(z_score(t1Dark_array)))\n",
    "\n",
    "plt.plot(z_scores)\n",
    "\n",
    "plt.xlabel('Time (miliseconds' ,fontsize = 13)\n",
    "plt.ylabel('Z-Score', fontsize = 13)\n",
    "plt.xlim(left = 0)\n",
    "plt.xlim(right = 6000)\n",
    "plt.title('Z-scores', fontsize = 15)\n",
    "\n",
    "threshold = 3\n",
    "plt.plot(threshold*np.ones(len(z_scores)), label = 'threshold')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Modified z-score\n",
    "\n",
    "#### z(i) = 0.6745(x(i)-M)/ MAD\n",
    "\n",
    "Here, MAD = median(|x-M|)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_z_score(y):\n",
    "    '''\n",
    "    More robust statistics, using median instead of mean. The multiplier 0.6745 describes the 0.75th quartile\n",
    "    and MAD refers to Median Absolute Deviation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y -- array of data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    modified_z_scores array of modified z-scores\n",
    "\n",
    "    '''\n",
    "    median_int = np.median(y)\n",
    "    MAD = np.median([np.abs(y - median_int)])\n",
    "    modified_z_scores = 0.6745 * (y - median_int) / MAD\n",
    "    return modified_z_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_z_scores = np.array(abs(modified_z_score(t1Dark_array)))\n",
    "\n",
    "plt.plot(mod_z_scores)\n",
    "\n",
    "plt.xlabel('Time (miliseconds' ,fontsize = 13)\n",
    "plt.ylabel('Z-Score', fontsize = 13)\n",
    "plt.xlim(left = 0)\n",
    "plt.xlim(right = 6000)\n",
    "plt.title('Modified Z-scores', fontsize = 15)\n",
    "\n",
    "threshold = 3\n",
    "plt.plot(threshold*np.ones(len(mod_z_scores)), label = 'threshold')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Using Whitaker and Hayes’ modified Z-score based approach for spike detection\n",
    "\n",
    "#### z(i) = 0.6745 (∇x(i)-M) / MAD\n",
    "\n",
    "In this manner, distance between consecutive spectrum points is used to calculate Z-score.\n",
    "\n",
    "##### Original publication: Whitaker, D. A. and K. Hayes (2018). \"A simple algorithm for despiking Raman spectra.\" Chemometrics and Intelligent Laboratory Systems 179: 82-84.\n",
    "\n",
    "##### Code adapted from: Coca, N., 2021. Removing Spikes from Raman Spectra with Anomaly Detection. [online] Medium. Available at: <https://towardsdatascience.com/removing-spikes-from-raman-spectra-8a9fdda0ac22> [Accessed 10 September 2021]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deltaX(a):\n",
    "    '''\n",
    "    Calculated ∇x(i) for inputted data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a -- array representation of pupil data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    delta_y array storing ∇x(i) values\n",
    "\n",
    "    '''\n",
    "    dist = 0\n",
    "    delta_y = [] \n",
    "    for i in np.arange(len(a)-1):\n",
    "        dist = a[i+1] - a[i]\n",
    "        delta_y.append(dist)\n",
    "    return delta_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1Dark_delta = np.array(deltaX(t1Dark_array))\n",
    "y_modified_z_score = np.array(np.abs(modified_z_score(t1Dark_delta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_modified_z_score)\n",
    "\n",
    "plt.xlabel('Time (miliseconds' ,fontsize = 13)\n",
    "plt.ylabel('Modified Z-Score with delta x', fontsize = 13)\n",
    "plt.xlim(left = 0)\n",
    "plt.xlim(right = 6000)\n",
    "plt.title('Modified Z-scores', fontsize = 15)\n",
    "\n",
    "threshold = 5\n",
    "plt.plot(threshold*np.ones(len(mod_z_scores)), label = 'threshold')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes = abs(np.array(modified_z_score(t1Dark_delta))) > threshold\n",
    "\n",
    "plt.xlabel('Time (miliseconds' ,fontsize = 13)\n",
    "plt.ylabel('Spike present (0/1)', fontsize = 13)\n",
    "plt.plot(spikes, color = 'red')\n",
    "plt.title('Spikes: ' + str(np.sum(spikes)), fontsize = 15)\n",
    "plt.xlim(0, 6000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixer(y, spikes):\n",
    "    '''\n",
    "    Remove spikes using spike data, and replace them with nan. This will allow moving average to restore remaining data points\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y -- array to be cleaned\n",
    "    spikes -- list of spikes (indicates whether spike is present on given index with a boolean)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y_out -- original data without spike points\n",
    "\n",
    "    '''\n",
    "    # Copy y to not overwrite\n",
    "    y_out = y.copy() \n",
    "    for i in np.arange(len(spikes)):\n",
    "        \n",
    "        # If we have a spike in position i, remove this data point\n",
    "        if spikes[i] != False: \n",
    "            y_out[i] = np.nan\n",
    "    return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yVals = fixer(t1Dark_array, spikes)\n",
    "plt.plot(t1Dark_array)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(yVals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series1 = pd.Series(yVals)\n",
    "series1 = series1.ewm(span = 200).mean()\n",
    "plt.plot(t1Dark_array, label = 'original')\n",
    "plt.plot(series1, label = 'cleaned')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotCleanedData(pdSeries1, pdSeries2):\n",
    "    '''\n",
    "    Use all methods above to plot cleaned version for one trial of Dark and one trial of Light\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pdSeries1 -- pandas series of one trial (Dark condition)\n",
    "    pdSeries2 -- pandas series of one trial (Light condition)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    finalSeriesDark -- cleaned version of pupil data from Dark trial\n",
    "    finalSeriesLight -- cleaned version of pupil data from Light trial\n",
    "\n",
    "    '''\n",
    "    # Set custom threshold\n",
    "    threshold = 5\n",
    "    \n",
    "    # Copy original series to not alter them\n",
    "    a = pdSeries1.values.copy()\n",
    "    b = pdSeries2.values.copy()\n",
    "    \n",
    "    # Define a new function to fill in data; if nan's are present at start, fill only these in using the first real value\n",
    "    # Full bfill produces suboptimal fill for remaining nan's, however no nan's can be present at the start\n",
    "    def bfillStart(a):\n",
    "        if math.isnan(a[0]):\n",
    "            for i in range(len(a)):\n",
    "                if math.isnan(a[i]) == False:\n",
    "                    location = i\n",
    "                    value = a[i]\n",
    "                    break\n",
    "            for i in range(location):\n",
    "                a[i] = value\n",
    "        return a\n",
    "    \n",
    "    # Only perform this if there is an nan in the 0'th index\n",
    "    if math.isnan(a[0]):\n",
    "        a = bfillStart(a)\n",
    "        \n",
    "    if math.isnan(b[0]):\n",
    "        b = bfillStart(b)\n",
    "    \n",
    "    # Now perform the average fill, to allow remaining steps to be completed\n",
    "    a = avgFill(a)\n",
    "    b = avgFill(b)\n",
    "    \n",
    "    # Calculate delta X\n",
    "    delta_a = np.array(deltaX(a))\n",
    "    delta_b = np.array(deltaX(b))\n",
    "    \n",
    "    # Identify spikes\n",
    "    spikes1 = abs(np.array(modified_z_score(delta_a))) > threshold\n",
    "    spikes2 = abs(np.array(modified_z_score(delta_b))) > threshold\n",
    "    \n",
    "    # Remove spikes\n",
    "    yDark = fixer(a, spikes1)\n",
    "    yLight = fixer(b, spikes2)\n",
    "    \n",
    "    # Convert back to series and perform ewm\n",
    "    finalSeriesDark = pd.Series(yDark)\n",
    "    finalSeriesDark = finalSeriesDark.ewm(span = 200).mean()\n",
    "    finalSeriesLight = pd.Series(yLight)\n",
    "    finalSeriesLight = finalSeriesLight.ewm(span = 200).mean()\n",
    "    \n",
    "    # Plot data\n",
    "    plt.plot(finalSeriesDark, label = 'Dark')\n",
    "    plt.plot(finalSeriesLight, label = 'Light')\n",
    "    plt.xlabel(\"Time (miliseconds)\", fontsize = 13)\n",
    "    plt.ylabel(\"Pupil measure\", fontsize = 13)\n",
    "    plt.title(\"Pupil measure during dark and light screen\", fontsize = 15)\n",
    "    plt.legend()\n",
    "    plt.xlim(0, 6000)\n",
    "    plt.show()\n",
    "    \n",
    "    # Return modified series\n",
    "    return finalSeriesDark, finalSeriesLight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DarkCleaned1, LightCleaned1 = plotCleanedData(dfDark.Trial_1, dfLight.Trial_1)\n",
    "DarkCleaned2, LightCleaned2 = plotCleanedData(dfDark.Trial_2, dfLight.Trial_2)\n",
    "DarkCleaned3, LightCleaned3 = plotCleanedData(dfDark.Trial_3, dfLight.Trial_3)\n",
    "DarkCleaned4, LightCleaned4 = plotCleanedData(dfDark.Trial_4, dfLight.Trial_4)\n",
    "DarkCleaned5, LightCleaned5 = plotCleanedData(dfDark.Trial_5, dfLight.Trial_5)\n",
    "DarkCleaned6, LightCleaned6 = plotCleanedData(dfDark.Trial_6, dfLight.Trial_6)\n",
    "DarkCleaned7, LightCleaned7 = plotCleanedData(dfDark.Trial_7, dfLight.Trial_7)\n",
    "DarkCleaned8, LightCleaned8 = plotCleanedData(dfDark.Trial_8, dfLight.Trial_8)\n",
    "DarkCleaned9, LightCleaned9 = plotCleanedData(dfDark.Trial_9, dfLight.Trial_9)\n",
    "DarkCleaned10, LightCleaned10 = plotCleanedData(dfDark.Trial_10, dfLight.Trial_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_Dark = pd.concat([DarkCleaned1, DarkCleaned2, DarkCleaned3, DarkCleaned4, DarkCleaned5, DarkCleaned6, DarkCleaned7, DarkCleaned8, DarkCleaned9, DarkCleaned10], axis = 1)\n",
    "new_df_Light = pd.concat([LightCleaned1, LightCleaned2, LightCleaned3, LightCleaned4, LightCleaned5, LightCleaned6, LightCleaned7, LightCleaned8, LightCleaned9, LightCleaned10], axis = 1)\n",
    "\n",
    "print(new_df_Dark.head(10))\n",
    "print(new_df_Light.head(10))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
